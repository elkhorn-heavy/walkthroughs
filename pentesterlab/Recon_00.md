# PentesterLab - Recon 00

PentesterLab offers a series of reconnaissance ("recon") challenges designed to
teach basic security skills.

## Challenge Overview

In this challenge, the goal is to retrieve the `robots.txt` file from the
hackycorp.com website.

Grade: Easy

## Initial Analysis

Given that the objective is to retrieve a file from a web server, one common
approach is to use a web browser. The `robots.txt` file is traditionally stored
in the root directory of a website, so the URL to use is
https://hackycorp.com/robots.txt.

Once you retrieve the file, you'll find a message at the bottom indicating that
the challenge is solved, with the last line containing a key in the form of a
_UUID_.

## Takeaways

This challenge introduces the concept of the `robots.txt` file. This file is
intended to tell web crawlers which content to exclude from their crawls or
_indexing_. However, attackers can use it to find content that may not be
directly exposed on the website itself.

## Beyond the Challenge

### Alternative Methods to Solve the Challenge

While a web browser is the simplest way to retrieve the `robots.txt` file,
there are other methods you can use, such as the `curl` command-line tool.

### Using curl

The `curl` tool is a versatile command-line utility for transferring data from
or to a server. This method is particularly useful if you need to automate the
process or retrieve multiple files at once.

Here's how you can retrieve the `robots.txt` file with `curl`:

```sh
$ curl https://hackycorp.com/robots.txt
User-agent: *
Disallow: /

# You solved recon_00
# The key for this challenge is
# 00000000-0000-0000-0000-000000000000
```

> Note: the real challenge key has been replaced with a fake _UUID_.
